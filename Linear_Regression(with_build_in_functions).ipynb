{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "HdFBlffoO2co"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Feature (temp, rain, hum)\n",
    "features = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# # GT (apples, oranges)\n",
    "# gt = np.array([[56, 70], \n",
    "#                     [81, 101], \n",
    "#                     [119, 133], \n",
    "#                     [22, 37], \n",
    "#                     [103, 119],\n",
    "#                     [57, 69], \n",
    "#                     [80, 102], \n",
    "#                     [118, 132], \n",
    "#                     [21, 38], \n",
    "#                     [104, 118], \n",
    "#                     [57, 69], \n",
    "#                     [82, 100], \n",
    "#                     [118, 134], \n",
    "#                     [20, 38], \n",
    "#                     [102, 120]], \n",
    "#                    dtype='float32')\n",
    "\n",
    "gt = np.array([[1], \n",
    "                    [2], \n",
    "                    [1], \n",
    "                    [2], \n",
    "                    [1],\n",
    "                    [2], \n",
    "                    [2], \n",
    "                    [2], \n",
    "                    [1], \n",
    "                    [1], \n",
    "                    [1], \n",
    "                    [1], \n",
    "                    [1], \n",
    "                    [2], \n",
    "                    [2]], \n",
    "                   dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "GD06OXejPoQO"
   },
   "outputs": [],
   "source": [
    "feature = torch.from_numpy(features)\n",
    "gt_value = torch.from_numpy(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u6933Q-QSkJ"
   },
   "source": [
    "**Dataset and DataLoader :**  **Dataset** - helps to work with rows from feature and gt as tuples. **Dataloader** provides with batches whcih help us to split our data and work easly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLq_RntDP5F-",
    "outputId": "ece2e05f-880b-4843-c531-bd4a424b937c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[1.],\n",
       "         [2.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Define the dataset\n",
    "\n",
    "train_ds = TensorDataset(feature, gt_value)\n",
    "train_ds[0:3] # goes to gt and feature data and get 3 rows of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kzGpsh5vRE53"
   },
   "outputs": [],
   "source": [
    "# define batches and use DataLoader\n",
    "\n",
    "BATCH_SIZE = 5 \n",
    "train_dl = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NztkpAcR1e1",
    "outputId": "ed6e22c4-6439-4c52-cb86-6b4dfa304d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[91., 87., 65.],\n",
      "        [68., 96., 71.],\n",
      "        [69., 96., 70.],\n",
      "        [74., 66., 43.],\n",
      "        [91., 88., 64.]])\n",
      "tensor([[2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dl :\n",
    "  print(x)\n",
    "  print(y) \n",
    "  break # if I don't use break my for loop gets all the dl batch size (5 sets). But in this case, it takes only 2 sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSHH8xbXSa7s"
   },
   "source": [
    "**nn.Linear** : instead of initializing the WEIGHTS and BIASES manually, we can use nn.Linear module which already initialized for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaOKJ4YgSE3i",
    "outputId": "96926e20-3c6b-453a-a1d7-f6503eea31b9"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "my_model = nn.Sequential(nn.Linear(3,5), nn.Linear(5,3), nn.Linear(3,1)) # means 3 features amd 2 gt \n",
    "# print(my_model.weight)\n",
    "# print(my_model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDGyzIY2S9vT",
    "outputId": "cc2527d1-5e3c-4f99-cc75-815cde060ea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6872],\n",
       "        [ 1.3402],\n",
       "        [-2.8276],\n",
       "        [ 3.2949],\n",
       "        [ 0.2589],\n",
       "        [ 0.8057],\n",
       "        [ 1.4911],\n",
       "        [-2.7131],\n",
       "        [ 3.1765],\n",
       "        [ 0.2914],\n",
       "        [ 0.8381],\n",
       "        [ 1.4587],\n",
       "        [-2.9784],\n",
       "        [ 3.2625],\n",
       "        [ 0.1405]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "\n",
    "preds = my_model(feature)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxmH1uyUUIBf"
   },
   "source": [
    "**Loss Function** : Alread has build-in form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3N8jF2ojT0Yq",
    "outputId": "af6cf05c-47f3-4853-bf74-74999f0132c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5109, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "my_loss_function = F.mse_loss # mse_loss is MeanSquareError build in function as mse_loss\n",
    "\n",
    "loss = my_loss_function(my_model(feature),gt_value ) # just apply my model to the feature not to the gt\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qzdBmsbVqRV"
   },
   "source": [
    "If i have certain question about something like models : just use : **?nn.Linear** which gives the all info. about the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2yIVw08WFJd"
   },
   "source": [
    "**OPTIMIZATION :** Instead of using grad. as I did without build-in functions, I can use the build in function **SGD (stochastic gradient descent) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "8W86VYBKVP2R"
   },
   "outputs": [],
   "source": [
    "# defining my optimizer\n",
    "\n",
    "my_optimizer = torch.optim.SGD(my_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uobsEtomZboe"
   },
   "source": [
    "### **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "kRWnRnfDWtQ5"
   },
   "outputs": [],
   "source": [
    "def  my_train_model(num_epoch, my_optimizer, loss, my_model):\n",
    "    for epoch in range (num_epoch):\n",
    "        for x , y in train_dl:\n",
    "            pred = my_model(x) # generate a prediction\n",
    "            loss = my_loss_function(pred, y) # calculate my loss value\n",
    "            my_optimizer.zero_grad() # reset the derivatives to 0\n",
    "            loss.backward() # compute derivatives\n",
    "            my_optimizer.step() # update the parameters by uing the derivatives \n",
    "            \n",
    "            # process\n",
    "        if (epoch + 1 ) % 10 == 0:\n",
    "            print('Epoch[{}/{}], Loss: {:.4f}'.format(epoch+1, num_epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHVOmzGwfhV-",
    "outputId": "2939a5fb-3fab-4692-f10d-db37b3377c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/100], Loss: 0.4126\n",
      "Epoch[20/100], Loss: 0.3545\n",
      "Epoch[30/100], Loss: 0.1584\n",
      "Epoch[40/100], Loss: 0.1504\n",
      "Epoch[50/100], Loss: 0.1889\n",
      "Epoch[60/100], Loss: 0.2818\n",
      "Epoch[70/100], Loss: 0.1078\n",
      "Epoch[80/100], Loss: 0.2850\n",
      "Epoch[90/100], Loss: 0.3668\n",
      "Epoch[100/100], Loss: 0.3780\n"
     ]
    }
   ],
   "source": [
    "my_train_model(100, my_optimizer,loss,my_model) # I don't have to forget the order of parms. when i am passing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuA7UTR6fwQJ",
    "outputId": "478d44db-1592-4c30-b060-2b79c135507a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = my_model(feature)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "wc3cvlNMiPTm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
